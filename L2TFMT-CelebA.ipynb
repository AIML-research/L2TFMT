{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.chdir(\"/yourpath/CelebA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3,0\" #list the gpu cores in the order you want to use e.g \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('list_attr_celeba.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ft=f.split('\\n')[1].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([r.split() for r in f.split('\\n')[2:-1]])\n",
    "ids=X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202599, 41)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to load for CelebA-Age use the block below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=X[:,Ft.index('Young')+1]\n",
    "y=np.array([X[:,i+1] for i in range(len(Ft)) if i!=Ft.index('Young')])\n",
    "y=[[0 if t[i]=='-1' else 1 for i in range(len(t))] for t in y]\n",
    "g=np.array([0 if g[i]=='-1' else 1 for i in range(len(g))])\n",
    "no_tasks=[4,10,17,13,14,17,26,29,35]\n",
    "y=np.array([y[t] for t in range(len(y)) if t not in no_tasks])\n",
    "Ft.remove('Young')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to load for CelebA-Gender use the block below instead of the block above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=X[:,Ft.index('Male')+1]\n",
    "y=np.array([X[:,i+1] for i in range(len(Ft)) if i!=Ft.index('Male')])\n",
    "y=[[0 if t[i]=='-1' else 1 for i in range(len(t))] for t in y]\n",
    "g=np.array([0 if g[i]=='-1' else 1 for i in range(len(g))])\n",
    "tasks=[2,3,5,6,7,8,11,12,19,20,22,24,26,30,31,32,38]\n",
    "y=np.array([y[t] for t in tasks])\n",
    "Ft.remove('Male')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here onwards all the blocks are common for both CelebA-Gender and CelebA-Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.models as pretrain\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = \"/yourpath/CelebA/celeba/\"\n",
    "image_size = 64\n",
    "batch_size = 8192\n",
    "workers = 2\n",
    "\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pre=pretrain.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "cpu=torch.device('cpu')\n",
    "dv=torch.device(\"cuda\" if (torch.cuda.is_available() ) else \"cpu\")#\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=np.arange(len(ids))\n",
    "in_tr,in_val,in_ts=indices[:162770],indices[162770:182637],indices[182637:]\n",
    "in_tr1=in_tr[:5*batch_size]; in_tr2=in_tr[5*batch_size:10*batch_size]; in_tr3=in_tr[10*batch_size:15*batch_size]\n",
    "in_tr4=in_tr[15*batch_size:]\n",
    "in_val1,in_val2=in_val[:10000],in_val[10000:]\n",
    "\n",
    "dataset_tr1 = torch.utils.data.Subset(dataset, in_tr1)\n",
    "dataset_tr2 = torch.utils.data.Subset(dataset, in_tr2)\n",
    "dataset_tr3 = torch.utils.data.Subset(dataset, in_tr3)\n",
    "dataset_tr4 = torch.utils.data.Subset(dataset, in_tr4)\n",
    "dataset_val1 = torch.utils.data.Subset(dataset, in_val1)\n",
    "dataset_val2 = torch.utils.data.Subset(dataset, in_val2)\n",
    "dataset_ts = torch.utils.data.Subset(dataset, in_ts)\n",
    "\n",
    "dataloader1 = torch.utils.data.DataLoader(dataset_tr1, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "dataloader2 = torch.utils.data.DataLoader(dataset_tr2, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "dataloader3 = torch.utils.data.DataLoader(dataset_tr3, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "dataloader4 = torch.utils.data.DataLoader(dataset_tr4, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "\n",
    "dataloader_val1 = torch.utils.data.DataLoader(dataset_val1, batch_size=10000,\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "dataloader_val2 = torch.utils.data.DataLoader(dataset_val2, batch_size=10000,\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_ts, batch_size=len(in_ts),\n",
    "                                         shuffle=False, num_workers=workers)\n",
    "\n",
    "\n",
    "y_test=[y[i][in_ts] for i in range(len(y))]\n",
    "\n",
    "y_v1,y_v2=[y[i][in_val1] for i in range(len(y))],[y[i][in_val2] for i in range(len(y))]\n",
    "\n",
    "y_tr1,y_tr2=[y[i][in_tr1] for i in range(len(y))],[y[i][in_tr2] for i in range(len(y))]\n",
    "y_tr3,y_tr4=[y[i][in_tr3] for i in range(len(y))],[y[i][in_tr4] for i in range(len(y))]\n",
    "\n",
    "\n",
    "\n",
    "g_tr1,g_tr2,g_tr3,g_tr4=g[in_tr1],g[in_tr2],g[in_tr3],g[in_tr4]\n",
    "g_val1,g_val2=g[in_val1],g[in_val2]\n",
    "g_test=g[in_ts]\n",
    "N_tasks=len(y)#4#2#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_v=[dataloader_val1,dataloader_val2]\n",
    "yv=[y_v1,y_v2]\n",
    "gv=[g_val1,g_val2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for par in model_pre.parameters():\n",
    "    par.requires_grad=False\n",
    "in_fc=model_pre.fc.in_features\n",
    "model_pre.fc=nn.Linear(in_fc,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTL(nn.Module):\n",
    "\n",
    "    def __init__(self,pretrain,tasks=2):\n",
    "        super(MTL, self).__init__()\n",
    "        self.tasks=tasks\n",
    "        self.fc1 = pretrain\n",
    "        self.bn1= nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.fc4 = nn.Linear(1024,1024)\n",
    "        self.tasks_out=nn.ModuleDict({str(t):nn.Linear(128,2) for t in range(self.tasks)})\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        \n",
    "        x = F.relu(self.bn3(self.fc4(x)))\n",
    "        \n",
    "        x = F.relu(self.bn2(self.fc2(x)))        \n",
    "        x = F.relu(self.fc3(x))\n",
    "\n",
    "        t=[self.tasks_out[str(i)](x) for i in range(self.tasks)]\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_loss(output,target,x_control):\n",
    "    prot_att=x_control\n",
    "    index_prot=torch.squeeze(torch.nonzero(prot_att[:] != 1.))\n",
    "    target_prot=torch.index_select(target, 0, index=index_prot)\n",
    "    index_prot_pos=torch.squeeze(torch.nonzero(target_prot[:] == 1. ))\n",
    "    index_prot_neg=torch.squeeze(torch.nonzero(target_prot[:] == 0. ))\n",
    "\n",
    "    index_non_prot=torch.squeeze(torch.nonzero(prot_att[:] == 1.))\n",
    "    target_non_prot=torch.index_select(target, 0, index=index_non_prot)\n",
    "    index_non_prot_pos=torch.squeeze(torch.nonzero(target_non_prot[:] == 1. ))\n",
    "    index_non_prot_neg=torch.squeeze(torch.nonzero(target_non_prot[:] == 0. ))\n",
    "\n",
    "    l_prot_pos=F.cross_entropy(torch.index_select(output, 0, index=index_prot_pos),torch.index_select(target, 0, index=index_prot_pos))    \n",
    "    l_non_prot_pos=F.cross_entropy(torch.index_select(output, 0, index=index_non_prot_pos),torch.index_select(target, 0, index=index_non_prot_pos))    \n",
    "    l_non_prot_neg=F.cross_entropy(torch.index_select(output, 0, index=index_non_prot_neg),torch.index_select(target, 0, index=index_non_prot_neg))\n",
    "    l_prot_neg=F.cross_entropy(torch.index_select(output, 0, index=index_prot_neg),torch.index_select(target, 0, index=index_prot_neg))    \n",
    "\n",
    "    for l in [l_prot_pos,l_non_prot_pos,l_prot_neg,l_non_prot_neg]:\n",
    "        if torch.isinf(l)==True:\n",
    "            l=torch.zeros_like(l,requires_grad=True)\n",
    "    dl_pos=torch.max(l_prot_pos,l_non_prot_pos)\n",
    "    dl_neg=torch.max(l_prot_neg,l_non_prot_neg)\n",
    "    L=dl_pos+dl_neg\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "acc = torchmetrics.Accuracy()\n",
    "def DM_rate(output,target,x_control):\n",
    "    prot_att=x_control\n",
    "    index_prot=torch.squeeze(torch.nonzero(prot_att[:] != 1.))\n",
    "    target_prot=torch.index_select(target, 0, index=index_prot)\n",
    "    index_prot_pos=torch.squeeze(torch.nonzero(target_prot[:] == 1. ))\n",
    "    index_prot_neg=torch.squeeze(torch.nonzero(target_prot[:] == 0. ))\n",
    "\n",
    "    index_non_prot=torch.squeeze(torch.nonzero(prot_att[:] == 1.))\n",
    "    target_non_prot=torch.index_select(target, 0, index=index_non_prot)\n",
    "    index_non_prot_pos=torch.squeeze(torch.nonzero(target_non_prot[:] == 1. ))\n",
    "    index_non_prot_neg=torch.squeeze(torch.nonzero(target_non_prot[:] == 0. ))\n",
    "\n",
    "    if index_prot_pos.shape==torch.Size([]) or index_prot_pos.shape==torch.Size([0])\\\n",
    "        or index_non_prot_pos.shape==torch.Size([]) or index_non_prot_pos.shape==torch.Size([0]):\n",
    "            l_prot_pos=torch.tensor(0.0001)\n",
    "            l_non_prot_pos=torch.tensor(0.0001)\n",
    "    else:        \n",
    "            l_prot_pos=acc(torch.index_select(output, 0, index=index_prot_pos),torch.index_select(target, 0, index=index_prot_pos))    \n",
    "            l_non_prot_pos=acc(torch.index_select(output, 0, index=index_non_prot_pos),torch.index_select(target, 0, index=index_non_prot_pos))    \n",
    "    \n",
    "    if index_prot_neg.shape==torch.Size([]) or index_prot_neg.shape==torch.Size([0])\\\n",
    "        or index_non_prot_neg.shape==torch.Size([]) or index_non_prot_neg.shape==torch.Size([0]):\n",
    "            l_prot_neg=torch.tensor(0.0001)\n",
    "            l_non_prot_neg=torch.tensor(0.0001)\n",
    "    else:        \n",
    "            l_prot_neg=acc(torch.index_select(output, 0, index=index_prot_neg),torch.index_select(target, 0, index=index_prot_neg))    \n",
    "            l_non_prot_neg=acc(torch.index_select(output, 0, index=index_non_prot_neg),torch.index_select(target, 0, index=index_non_prot_neg))  \n",
    "            \n",
    "    dl_pos=torch.abs(l_prot_pos-l_non_prot_pos)\n",
    "    dl_neg=torch.abs(l_prot_neg-l_non_prot_neg)\n",
    "    DM=dl_pos+dl_neg\n",
    "    \n",
    "    return DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, fc1_dims, fc2_dims,fc3_dims=256,\n",
    "                 n_actions=2,n_tasks=2):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        self.tasks=n_tasks\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.bn1= nn.LayerNorm(fc1_dims)\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.bn2= nn.LayerNorm(fc2_dims)\n",
    "        self.fc3_dims = fc3_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.fc1 = nn.Linear(self.input_dims, self.fc1_dims)\n",
    "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "        self.fc3 = nn.Linear(self.fc2_dims, self.fc3_dims)\n",
    "        self.fc_out=nn.ModuleDict({str(t):nn.Linear(self.fc3_dims, self.n_actions) for t in range(self.tasks)})\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.bn1(self.fc1(state)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = F.relu(self.fc3(x))\n",
    "\n",
    "        Q_sa=[self.fc_out[str(i)](x) for i in range(self.tasks)]\n",
    "\n",
    "        return Q_sa#Q1_sa,Q2_sa#,Q3_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gamma=0.9\n",
    "omega_T=torch.tensor([1/N_tasks for t in range(N_tasks)]).to(dv)\n",
    "init_loss_T=[None for t in range(N_tasks)]\n",
    "criteria_t=nn.MSELoss()\n",
    "def Teacher(state,state_a,state_b,R_a,R_b,DqN,opti_T):\n",
    "    grads,G_n,loss_ratio=[],[],[]\n",
    "    global init_loss_T\n",
    "    global omega_T\n",
    "    opti_T.zero_grad()\n",
    "    for t in range(N_tasks):        \n",
    "        Q_S=DqN(state[t])[t]\n",
    "        target=[]\n",
    "        with torch.no_grad():\n",
    "            Q_sa=R_a[t]+gamma*torch.max(DqN(state_a[t])[t],1)[0]\n",
    "            Q_sb=R_b[t]+gamma*torch.max(DqN(state_b[t])[t],1)[0]\n",
    "        target=torch.tensor([[Q_sa[i],Q_sb[i]] for i in range(len(Q_sa))]).to(dv)\n",
    "        teach_loss=criteria_t(Q_S,target)\n",
    "        teach_loss.backward()\n",
    "        if init_loss_T[t]== None:\n",
    "            init_loss_T[t]=teach_loss.item()\n",
    "        loss_ratio.append(teach_loss.item()/init_loss_T[t])\n",
    "        grads_sh={}\n",
    "        for n,p in DqN.named_parameters():\n",
    "            if p.data.shape[0]!=2 and p.grad!=None:\n",
    "                grads_sh[n] = p.grad \n",
    "                \n",
    "        grads.append(grads_sh)\n",
    "        G_n.append(torch.linalg.norm(torch.stack([torch.linalg.norm(grads_sh[g]) for g in grads_sh])))\n",
    "    G_n = torch.stack(G_n)\n",
    "    E_t = sum(loss_ratio)/len(loss_ratio)\n",
    "    r_t=[loss/E_t for loss in loss_ratio] #relative inverse trainin g rate of teacher\n",
    "    omega_T,DqN = Update_model(DqN,grads,omega_T,G_n,r_t,opti_T)\n",
    "    torch.save(omega_T,'/yourpath/CelebA/model/age/omega_T.pt') # \n",
    "                   \n",
    "    return DqN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "def Update_model(model,grads_sh,omega,G_n,r_t,opti):\n",
    "    loss_gn=[(G_n[t]-torch.mean(G_n)*r_t[t]) for t in range(len(G_n))]\n",
    "    for i in range(len(G_n)):\n",
    "        d_l=0\n",
    "        if loss_gn[i]>0:\n",
    "            d_l+=(len(G_n)-1)/len(G_n)*G_n[i]\n",
    "        elif loss_gn[i]<0:\n",
    "            d_l-=(len(G_n)-1)/len(G_n)*G_n[i]\n",
    "        for j in range(len(G_n)):\n",
    "            if j!=i:\n",
    "                if loss_gn[j]>0:\n",
    "                    d_l-=(G_n[i]/len(G_n))\n",
    "                elif loss_gn[j]<0:\n",
    "                    d_l+=(G_n[i]/len(G_n))\n",
    "        \n",
    "        omega[i]-=lr*d_l\n",
    "        omega[i]=1\n",
    "    for t in range(len(G_n)):\n",
    "        for n,p in model.named_parameters():\n",
    "            if p.data.shape[0]!=2 and p.grad!=None:\n",
    "                if t==0:\n",
    "                    p.grad=omega[t]*grads_sh[t][n]\n",
    "                else:\n",
    "                    p.grad+=omega[t]*grads_sh[t][n]\n",
    "                    \n",
    "    opti.step() \n",
    "    for i in range(len(omega)):\n",
    "        if omega[i]<0:\n",
    "            omega[i]=-omega[i]\n",
    "    return omega,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=MTL(model_pre.to(dv),tasks=N_tasks)\n",
    "net=nn.DataParallel(net)\n",
    "net.to(dv)\n",
    "opti_S=optim.AdamW(params=net.parameters())\n",
    "\n",
    "flat_w=torch.flatten(net.module.tasks_out['0'].weight)\n",
    "dqn=DeepQNetwork(len(flat_w),512,512,n_actions=2,n_tasks=N_tasks).to(dv)\n",
    "opti_T = optim.AdamW(dqn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Student(stud,path,action,X,y,t=0,xc=None):\n",
    "    stud.load_state_dict(torch.load(path))\n",
    "    opti = optim.Adam(stud.parameters())\n",
    "    opti.zero_grad()\n",
    "    out=stud(X)[t]\n",
    "    if xc!=None:\n",
    "        loss=action(out,y,xc)        \n",
    "    else:\n",
    "        loss=action(out,y)\n",
    "    #print(loss)\n",
    "    loss.backward()\n",
    "    opti.step()\n",
    "    return stud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  14 Loss pointers [[1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0], [1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0], [1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0]]\n",
      "Task 0   Acc: tensor(0.8883) EO: tensor(0.0325)\n",
      "Task 1   Acc: tensor(0.7299) EO: tensor(0.0248)\n",
      "Task 2   Acc: tensor(0.5923) EO: tensor(0.0250)\n",
      "Task 3   Acc: tensor(0.7929) EO: tensor(0.0090)\n",
      "Task 4   Acc: tensor(0.8526) EO: tensor(0.0130)\n",
      "Task 5   Acc: tensor(0.7529) EO: tensor(0.0101)\n",
      "Task 6   Acc: tensor(0.7696) EO: tensor(0.0146)\n",
      "Task 7   Acc: tensor(0.7696) EO: tensor(0.0058)\n",
      "Task 8   Acc: tensor(0.8484) EO: tensor(0.0037)\n",
      "Task 9   Acc: tensor(0.7894) EO: tensor(0.0220)\n",
      "Task 10   Acc: tensor(0.8641) EO: tensor(0.0121)\n",
      "Task 11   Acc: tensor(0.9333) EO: tensor(0.0165)\n",
      "Task 12   Acc: tensor(0.9397) EO: tensor(0.0177)\n",
      "Task 13   Acc: tensor(0.6138) EO: tensor(0.0181)\n",
      "Task 14   Acc: tensor(0.5693) EO: tensor(0.0119)\n",
      "Task 15   Acc: tensor(0.6159) EO: tensor(0.0063)\n",
      "Task 16   Acc: tensor(0.5273) EO: tensor(0.0197)\n",
      "Task 17   Acc: tensor(0.9634) EO: tensor(0.0102)\n",
      "Task 18   Acc: tensor(0.8794) EO: tensor(0.0244)\n",
      "Task 19   Acc: tensor(0.8411) EO: tensor(0.0229)\n",
      "Task 20   Acc: tensor(0.7217) EO: tensor(0.0107)\n",
      "Task 21   Acc: tensor(0.7141) EO: tensor(0.0123)\n",
      "Task 22   Acc: tensor(0.9185) EO: tensor(0.0110)\n",
      "Task 23   Acc: tensor(0.9455) EO: tensor(0.0085)\n",
      "Task 24   Acc: tensor(0.5680) EO: tensor(0.0154)\n",
      "Task 25   Acc: tensor(0.7975) EO: tensor(0.0273)\n",
      "Task 26   Acc: tensor(0.6747) EO: tensor(0.0068)\n",
      "Task 27   Acc: tensor(0.8095) EO: tensor(0.0168)\n",
      "Task 28   Acc: tensor(0.6513) EO: tensor(0.0181)\n",
      "Task 29   Acc: tensor(0.8747) EO: tensor(0.0475)\n",
      "Task 30   Acc: tensor(0.9285) EO: tensor(0.0270)\n",
      "Epoch:  15 Loss pointers [[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0], [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0], [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0]]\n",
      "Task 0   Acc: tensor(0.8875) EO: tensor(0.0507)\n",
      "Task 1   Acc: tensor(0.7335) EO: tensor(0.0081)\n",
      "Task 2   Acc: tensor(0.5879) EO: tensor(0.0088)\n",
      "Task 3   Acc: tensor(0.7945) EO: tensor(0.0045)\n",
      "Task 4   Acc: tensor(0.8504) EO: tensor(0.0117)\n",
      "Task 5   Acc: tensor(0.7616) EO: tensor(0.0234)\n",
      "Task 6   Acc: tensor(0.7667) EO: tensor(0.0227)\n",
      "Task 7   Acc: tensor(0.7580) EO: tensor(0.0194)\n",
      "Task 8   Acc: tensor(0.8547) EO: tensor(0.0269)\n",
      "Task 9   Acc: tensor(0.7976) EO: tensor(0.0287)\n",
      "Task 10   Acc: tensor(0.8544) EO: tensor(0.0212)\n",
      "Task 11   Acc: tensor(0.9354) EO: tensor(0.0017)\n",
      "Task 12   Acc: tensor(0.9405) EO: tensor(0.0008)\n",
      "Task 13   Acc: tensor(0.6205) EO: tensor(0.0062)\n",
      "Task 14   Acc: tensor(0.5788) EO: tensor(0.0286)\n",
      "Task 15   Acc: tensor(0.6042) EO: tensor(0.0036)\n",
      "Task 16   Acc: tensor(0.5365) EO: tensor(0.0107)\n",
      "Task 17   Acc: tensor(0.9593) EO: tensor(0.0085)\n",
      "Task 18   Acc: tensor(0.8873) EO: tensor(0.0210)\n",
      "Task 19   Acc: tensor(0.8371) EO: tensor(0.0364)\n",
      "Task 20   Acc: tensor(0.7192) EO: tensor(0.0274)\n",
      "Task 21   Acc: tensor(0.7182) EO: tensor(0.0140)\n",
      "Task 22   Acc: tensor(0.9190) EO: tensor(0.0384)\n",
      "Task 23   Acc: tensor(0.9444) EO: tensor(0.0108)\n",
      "Task 24   Acc: tensor(0.5748) EO: tensor(0.0175)\n",
      "Task 25   Acc: tensor(0.7914) EO: tensor(0.0255)\n",
      "Task 26   Acc: tensor(0.6786) EO: tensor(0.0301)\n",
      "Task 27   Acc: tensor(0.8132) EO: tensor(0.0129)\n",
      "Task 28   Acc: tensor(0.6543) EO: tensor(0.0102)\n",
      "Task 29   Acc: tensor(0.8767) EO: tensor(0.0010)\n",
      "Task 30   Acc: tensor(0.9250) EO: tensor(0.0205)\n",
      "Epoch:  16 Loss pointers [[1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0], [1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0], [1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0]]\n",
      "Task 0   Acc: tensor(0.8873) EO: tensor(0.0319)\n",
      "Task 1   Acc: tensor(0.7277) EO: tensor(0.0909)\n",
      "Task 2   Acc: tensor(0.5899) EO: tensor(0.0195)\n",
      "Task 3   Acc: tensor(0.7950) EO: tensor(0.0264)\n",
      "Task 4   Acc: tensor(0.8507) EO: tensor(0.0468)\n",
      "Task 5   Acc: tensor(0.7586) EO: tensor(0.0120)\n",
      "Task 6   Acc: tensor(0.7649) EO: tensor(0.0295)\n",
      "Task 7   Acc: tensor(0.7588) EO: tensor(0.0193)\n",
      "Task 8   Acc: tensor(0.8510) EO: tensor(0.0385)\n",
      "Task 9   Acc: tensor(0.7927) EO: tensor(0.0176)\n",
      "Task 10   Acc: tensor(0.8589) EO: tensor(0.0404)\n",
      "Task 11   Acc: tensor(0.9326) EO: tensor(0.0263)\n",
      "Task 12   Acc: tensor(0.9381) EO: tensor(0.0337)\n",
      "Task 13   Acc: tensor(0.6246) EO: tensor(0.0357)\n",
      "Task 14   Acc: tensor(0.5734) EO: tensor(0.0181)\n",
      "Task 15   Acc: tensor(0.6208) EO: tensor(0.0194)\n",
      "Task 16   Acc: tensor(0.5414) EO: tensor(0.0121)\n",
      "Task 17   Acc: tensor(0.9576) EO: tensor(0.0231)\n",
      "Task 18   Acc: tensor(0.8871) EO: tensor(0.0306)\n",
      "Task 19   Acc: tensor(0.8339) EO: tensor(0.0232)\n",
      "Task 20   Acc: tensor(0.7125) EO: tensor(0.0091)\n",
      "Task 21   Acc: tensor(0.7201) EO: tensor(0.0407)\n",
      "Task 22   Acc: tensor(0.9181) EO: tensor(0.0116)\n",
      "Task 23   Acc: tensor(0.9441) EO: tensor(0.0168)\n",
      "Task 24   Acc: tensor(0.5671) EO: tensor(0.0309)\n",
      "Task 25   Acc: tensor(0.7948) EO: tensor(0.0113)\n",
      "Task 26   Acc: tensor(0.6756) EO: tensor(0.0096)\n",
      "Task 27   Acc: tensor(0.8097) EO: tensor(0.0192)\n",
      "Task 28   Acc: tensor(0.6617) EO: tensor(0.0292)\n",
      "Task 29   Acc: tensor(0.8761) EO: tensor(0.0105)\n",
      "Task 30   Acc: tensor(0.9261) EO: tensor(0.0342)\n",
      "Epoch:  17 Loss pointers [[1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0], [1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0], [1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0]]\n",
      "Task 0   Acc: tensor(0.8883) EO: tensor(0.0325)\n",
      "Task 1   Acc: tensor(0.7299) EO: tensor(0.0248)\n",
      "Task 2   Acc: tensor(0.5971) EO: tensor(0.0282)\n",
      "Task 3   Acc: tensor(0.7929) EO: tensor(0.0090)\n",
      "Task 4   Acc: tensor(0.8526) EO: tensor(0.0130)\n",
      "Task 5   Acc: tensor(0.7529) EO: tensor(0.0101)\n",
      "Task 6   Acc: tensor(0.7696) EO: tensor(0.0146)\n",
      "Task 7   Acc: tensor(0.7696) EO: tensor(0.0058)\n",
      "Task 8   Acc: tensor(0.8484) EO: tensor(0.0037)\n",
      "Task 9   Acc: tensor(0.7894) EO: tensor(0.0220)\n",
      "Task 10   Acc: tensor(0.8641) EO: tensor(0.0121)\n",
      "Task 11   Acc: tensor(0.9333) EO: tensor(0.0165)\n",
      "Task 12   Acc: tensor(0.9397) EO: tensor(0.0177)\n",
      "Task 13   Acc: tensor(0.6207) EO: tensor(0.0136)\n",
      "Task 14   Acc: tensor(0.5825) EO: tensor(0.0180)\n",
      "Task 15   Acc: tensor(0.6267) EO: tensor(0.0093)\n",
      "Task 16   Acc: tensor(0.5329) EO: tensor(0.0217)\n",
      "Task 17   Acc: tensor(0.9634) EO: tensor(0.0102)\n",
      "Task 18   Acc: tensor(0.8794) EO: tensor(0.0244)\n",
      "Task 19   Acc: tensor(0.8411) EO: tensor(0.0229)\n",
      "Task 20   Acc: tensor(0.7217) EO: tensor(0.0107)\n",
      "Task 21   Acc: tensor(0.7141) EO: tensor(0.0123)\n",
      "Task 22   Acc: tensor(0.9185) EO: tensor(0.0110)\n",
      "Task 23   Acc: tensor(0.9455) EO: tensor(0.0085)\n",
      "Task 24   Acc: tensor(0.5711) EO: tensor(0.0225)\n",
      "Task 25   Acc: tensor(0.7975) EO: tensor(0.0273)\n",
      "Task 26   Acc: tensor(0.6747) EO: tensor(0.0068)\n",
      "Task 27   Acc: tensor(0.8095) EO: tensor(0.0168)\n",
      "Task 28   Acc: tensor(0.6558) EO: tensor(0.0127)\n",
      "Task 29   Acc: tensor(0.8747) EO: tensor(0.0475)\n",
      "Task 30   Acc: tensor(0.9285) EO: tensor(0.0270)\n",
      "Epoch:  18 Loss pointers [[1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0], [1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0], [1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]]\n",
      "Task 0   Acc: tensor(0.8883) EO: tensor(0.0325)\n",
      "Task 1   Acc: tensor(0.7299) EO: tensor(0.0248)\n",
      "Task 2   Acc: tensor(0.5995) EO: tensor(0.0339)\n",
      "Task 3   Acc: tensor(0.7929) EO: tensor(0.0090)\n",
      "Task 4   Acc: tensor(0.8526) EO: tensor(0.0130)\n",
      "Task 5   Acc: tensor(0.7529) EO: tensor(0.0101)\n",
      "Task 6   Acc: tensor(0.7696) EO: tensor(0.0146)\n",
      "Task 7   Acc: tensor(0.7696) EO: tensor(0.0058)\n",
      "Task 8   Acc: tensor(0.8484) EO: tensor(0.0037)\n",
      "Task 9   Acc: tensor(0.7894) EO: tensor(0.0220)\n",
      "Task 10   Acc: tensor(0.8641) EO: tensor(0.0121)\n",
      "Task 11   Acc: tensor(0.9333) EO: tensor(0.0165)\n",
      "Task 12   Acc: tensor(0.9397) EO: tensor(0.0177)\n",
      "Task 13   Acc: tensor(0.6225) EO: tensor(0.0160)\n",
      "Task 14   Acc: tensor(0.5802) EO: tensor(0.0122)\n",
      "Task 15   Acc: tensor(0.6321) EO: tensor(0.0066)\n",
      "Task 16   Acc: tensor(0.5325) EO: tensor(0.0174)\n",
      "Task 17   Acc: tensor(0.9634) EO: tensor(0.0102)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 18   Acc: tensor(0.8794) EO: tensor(0.0244)\n",
      "Task 19   Acc: tensor(0.8411) EO: tensor(0.0229)\n",
      "Task 20   Acc: tensor(0.7217) EO: tensor(0.0107)\n",
      "Task 21   Acc: tensor(0.7141) EO: tensor(0.0123)\n",
      "Task 22   Acc: tensor(0.9185) EO: tensor(0.0110)\n",
      "Task 23   Acc: tensor(0.9455) EO: tensor(0.0085)\n",
      "Task 24   Acc: tensor(0.5711) EO: tensor(0.0210)\n",
      "Task 25   Acc: tensor(0.7975) EO: tensor(0.0273)\n",
      "Task 26   Acc: tensor(0.6747) EO: tensor(0.0068)\n",
      "Task 27   Acc: tensor(0.8095) EO: tensor(0.0168)\n",
      "Task 28   Acc: tensor(0.6602) EO: tensor(0.0057)\n",
      "Task 29   Acc: tensor(0.8747) EO: tensor(0.0475)\n",
      "Task 30   Acc: tensor(0.9285) EO: tensor(0.0270)\n"
     ]
    }
   ],
   "source": [
    "omega_S=torch.tensor([1/N_tasks for t in range(N_tasks)]).to(dv)\n",
    "init_loss_S=[None for t in range(N_tasks)]\n",
    "m_acc,flag=0.0,1\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "best_S=[[0,0] for t in range(N_tasks)]\n",
    "optim_path,optim_path_disc,optim_clas=[],[],[]\n",
    "path='/yourpath/CelebA/model/age/Model_l2tfmt.pt' #path to save your model\n",
    "path_t='/yourpath/CelebA/model/age/dqn_n.pt' ##path to save your teacher model\n",
    "torch.save(net.state_dict(),path)\n",
    "action_choices=[]\n",
    "stud=nn.DataParallel(MTL(model_pre,tasks=N_tasks)).to(dv)\n",
    "dt=[dataloader1,dataloader2,dataloader3,dataloader4]\n",
    "yt=[y_tr1,y_tr2,y_tr3,y_tr4]\n",
    "gt=[g_tr1,g_tr2,g_tr3,g_tr4]\n",
    "for epoch in range(20):  # loop over each NN multiple times\n",
    "    loss_pointer=[]\n",
    "    state_net,state_a,state_f=[[] for t in range(N_tasks)],[[] for t in range(N_tasks)],[[] for t in range(N_tasks)]\n",
    "    R_A,R_F=[[] for t in range(N_tasks)],[[] for t in range(N_tasks)]\n",
    "    ch=np.random.choice([0,1,2,3])\n",
    "    dataloader,y_train,g_train=dt[ch],yt[ch],gt[ch]\n",
    "    y_train=[torch.tensor(y_train[i]) for i in range(N_tasks)]\n",
    "    xg=torch.tensor(g_train)\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs =data[0]\n",
    "        if ((i+1)*batch_size)<len(in_tr):            \n",
    "            labels=[y_train[t][i*batch_size:(i+1)*batch_size] for t in range(N_tasks)]\n",
    "            xc=xg[i*batch_size:(i+1)*batch_size]\n",
    "        else:\n",
    "            labels=[y_train[t][i*batch_size:] for t in range(N_tasks)]\n",
    "            xc=xg[i*batch_size:]\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        net.load_state_dict(torch.load(path))\n",
    "        net.to(dv)\n",
    "        fg=[0 for i in range(N_tasks)]\n",
    "        with torch.no_grad():\n",
    "            for t in range(N_tasks):\n",
    "                flat=torch.flatten(net.module.tasks_out[str(t)].weight)\n",
    "                fg[t]=torch.argmax(dqn(flat)[t])\n",
    "                       \n",
    "        opti_S.zero_grad()\n",
    "        outputs = net(inputs.to(dv).float())\n",
    "        lp,grads,G_n,loss_ratio=[0 for t in range(N_tasks)],[],[],[]\n",
    "        for t in range(N_tasks):\n",
    "            \n",
    "            #MTL starts\n",
    "            loss_a=criteria(outputs[t], labels[t].to(dv))\n",
    "            loss_f=fair_loss(outputs[t], labels[t].to(dv),xc.to(dv))\n",
    "            if fg[t]==0:\n",
    "                loss_t=loss_a\n",
    "                lp[t]=0\n",
    "            else:\n",
    "                loss_t=loss_f\n",
    "                lp[t]=1\n",
    "            loss_t.backward(retain_graph=True)\n",
    "            \n",
    "            if init_loss_S[t]== None:\n",
    "                init_loss_S[t]=loss_t.item()\n",
    "            loss_ratio.append(loss_t.item()/init_loss_S[t])\n",
    "            grads_sh={}\n",
    "            for n,p in net.named_parameters():\n",
    "                if p.data.shape[0]!=2 and p.grad!=None:\n",
    "                    grads_sh[n] = p.grad\n",
    "                    p.grad=None\n",
    "            grads.append(grads_sh)\n",
    "            G_n.append(torch.linalg.norm(torch.stack([torch.linalg.norm(grads_sh[g]) for g in grads_sh])))\n",
    "        loss_pointer.append(lp)\n",
    "        G_n = torch.stack(G_n)\n",
    "        E_t = sum(loss_ratio)/len(loss_ratio)\n",
    "        r_t=[loss/E_t for loss in loss_ratio] #relative inverse trainin g rate of student\n",
    "        omega_S,net = Update_model(net,grads,omega_S,G_n,r_t,opti_S) \n",
    "        torch.save(net.state_dict(),path)\n",
    "        torch.save(omega_S,'/yourpath/CelebA/model/age/omega_S.pt')\n",
    "        for t in range(N_tasks):\n",
    "            state_net[t].append(torch.unsqueeze(torch.flatten(net.module.tasks_out[str(t)].weight),dim=0))\n",
    "\n",
    "            accuracy=acc(outputs[t].to(cpu),labels[t].to(cpu))\n",
    "            fairness=DM_rate(outputs[t].to(cpu), labels[t].to(cpu),xc.to(cpu))\n",
    "\n",
    "            learn_a=Student(stud,path,criteria,inputs.to(dv).float(),labels[t].to(dv),t=t)\n",
    "\n",
    "            learn_f=Student(stud,path,fair_loss,inputs.to(dv).float(),labels[t].to(dv),t=t,xc=xc.to(dv))\n",
    "\n",
    "\n",
    "            state_a[t].append(torch.unsqueeze(torch.flatten(learn_a.module.tasks_out[str(t)].weight),dim=0))            \n",
    "            state_f[t].append(torch.unsqueeze(torch.flatten(learn_f.module.tasks_out[str(t)].weight),dim=0))\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                out_A=learn_a(inputs.to(dv).float())[t]\n",
    "                out_F=learn_f(inputs.to(dv).float())[t]\n",
    "                acc_a=acc(out_A.to(cpu),labels[t].to(cpu))\n",
    "                DM_a=DM_rate(out_A.to(cpu),labels[t].to(cpu),xc.to(cpu))\n",
    "                acc_f=acc(out_F.to(cpu),labels[t].to(cpu))\n",
    "                DM_f=DM_rate(out_F.to(cpu),labels[t].to(cpu),xc.to(cpu))\n",
    "        \n",
    "            if best_S[t][0]==0:\n",
    "                best_S[t][0]=accuracy.item()\n",
    "                best_S[t][1]=fairness\n",
    "            # the reward functions\n",
    "            R_A[t].append(torch.min((acc_a-best_S[t][0])/best_S[t][0],(1-DM_a-best_S[t][1])/best_S[t][1]))\n",
    "            R_F[t].append(torch.min((acc_f-best_S[t][0])/best_S[t][0],(1-DM_f-best_S[t][1])/best_S[t][1]))\n",
    "        del inputs; del labels; del xc \n",
    "    for t in range(N_tasks):\n",
    "        state_net[t]=torch.cat(state_net[t],0).to(dv)\n",
    "        state_a[t]=torch.cat(state_a[t],0).to(dv)\n",
    "        state_f[t]=torch.cat(state_f[t],0).to(dv)\n",
    "        R_A[t]=torch.tensor(R_A[t]).to(dv)\n",
    "        R_F[t]=torch.tensor(R_F[t]).to(dv)\n",
    "    dqn=Teacher(state_net,state_a,state_f,R_A,R_F,dqn,opti_T)\n",
    "    torch.save(dqn.state_dict(),path_t)\n",
    "    del state_net; del state_a; del state_f; del R_A; del R_F\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        ch=np.random.choice([0,1])\n",
    "        val_batch,y_v,g_val=next(iter(d_v[ch]))[0],yv[ch],gv[ch]\n",
    "        pred0=net(val_batch.to(dv))#=Val_mod\n",
    "        print('Epoch: ',epoch, 'Loss pointers',loss_pointer)\n",
    "        action_choices.append(loss_pointer)\n",
    "        np.save(file=\"/yourpath/CelebA/loss_pointers_age_n.npy\",arr=np.array(action_choices)) \n",
    "        for t in range(N_tasks): \n",
    "            accuracy=acc(pred0[t].to(cpu),torch.tensor(y_v[t]))\n",
    "            EO=DM_rate(pred0[t].to(cpu),torch.tensor(y_v[t]),torch.tensor(g_val))\n",
    "            \n",
    "            print('Task',t,'  Acc:',accuracy, 'EO:',EO)\n",
    "            if accuracy>best_S[t][0]:\n",
    "                best_S[t][0]=accuracy\n",
    "            if 1-EO>best_S[t][1]:\n",
    "                best_S[t][1]=1-EO\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STL(nn.Module):\n",
    "\n",
    "    def __init__(self,pretrain):\n",
    "        super(STL, self).__init__()\n",
    "        self.fc1 = pretrain \n",
    "        self.bn1= nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.fc4 = nn.Linear(1024,1024)     \n",
    "        self.task = nn.Linear(128,2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        \n",
    "        x = F.relu(self.bn3(self.fc4(x)))\n",
    "        \n",
    "        x = F.relu(self.bn2(self.fc2(x)))        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        t = self.task(x)\n",
    "       \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaths={'path'+str(t):'/yourpath/CelebA/model/Model_stl'+str(t)+'.pt' for t in range(N_tasks)}\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch=next(iter(dataloader_test))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0   Acc: tensor(0.8859) DMs: tensor(0.0108)\n",
      "Task 1   Acc: tensor(0.7613) DMs: tensor(0.0206)\n",
      "Task 2   Acc: tensor(0.7063) DMs: tensor(0.0190)\n",
      "Task 3   Acc: tensor(0.7929) DMs: tensor(0.0137)\n",
      "Task 4   Acc: tensor(0.8771) DMs: tensor(0.0115)\n",
      "Task 5   Acc: tensor(0.7701) DMs: tensor(0.0136)\n",
      "Task 6   Acc: tensor(0.7801) DMs: tensor(0.0103)\n",
      "Task 7   Acc: tensor(0.8116) DMs: tensor(0.0121)\n",
      "Task 8   Acc: tensor(0.9135) DMs: tensor(0.0111)\n",
      "Task 9   Acc: tensor(0.8126) DMs: tensor(0.0416)\n",
      "Task 10   Acc: tensor(0.8565) DMs: tensor(0.0164)\n",
      "Task 11   Acc: tensor(0.9409) DMs: tensor(0.0115)\n",
      "Task 12   Acc: tensor(0.9385) DMs: tensor(0.0385)\n",
      "Task 13   Acc: tensor(0.7935) DMs: tensor(0.0015)\n",
      "Task 14   Acc: tensor(0.6843) DMs: tensor(0.0263)\n",
      "Task 15   Acc: tensor(0.8323) DMs: tensor(0.0165)\n",
      "Task 16   Acc: tensor(0.6191) DMs: tensor(0.0162)\n",
      "Task 17   Acc: tensor(0.9594) DMs: tensor(0.0106)\n",
      "Task 18   Acc: tensor(0.8792) DMs: tensor(0.0065)\n",
      "Task 19   Acc: tensor(0.8409) DMs: tensor(0.0046)\n",
      "Task 20   Acc: tensor(0.7269) DMs: tensor(0.0036)\n",
      "Task 21   Acc: tensor(0.7271) DMs: tensor(0.0303)\n",
      "Task 22   Acc: tensor(0.9174) DMs: tensor(0.0087)\n",
      "Task 23   Acc: tensor(0.9435) DMs: tensor(0.0056)\n",
      "Task 24   Acc: tensor(0.6796) DMs: tensor(0.0290)\n",
      "Task 25   Acc: tensor(0.7973) DMs: tensor(0.0369)\n",
      "Task 26   Acc: tensor(0.7655) DMs: tensor(0.0196)\n",
      "Task 27   Acc: tensor(0.8135) DMs: tensor(0.0369)\n",
      "Task 28   Acc: tensor(0.8159) DMs: tensor(0.0136)\n",
      "Task 29   Acc: tensor(0.8797) DMs: tensor(0.0015)\n",
      "Task 30   Acc: tensor(0.9317) DMs: tensor(0.0187)\n"
     ]
    }
   ],
   "source": [
    "snet=nn.DataParallel(STL(model_pre.to(device)))\n",
    "snet.to(device)\n",
    "Bests=[]\n",
    "for t in range(N_tasks):  \n",
    "    snet.load_state_dict(torch.load(spaths['path'+str(t)]))\n",
    "    pred0=snet(test_batch.to(device).float())\n",
    "    accuracy=acc(pred0.to(cpu),torch.tensor(y_test[t]).to(cpu))\n",
    "    DM=DM_rate(pred0.to(cpu),torch.tensor(y_test[t]).to(cpu),torch.tensor(g_test).to(cpu))\n",
    "    Bests.append([accuracy,DM])\n",
    "    print('Task',t,'  Acc:',accuracy, 'DMs:',DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "del snet\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): MTL(\n",
       "    (fc1): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "    (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc3): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (tasks_out): ModuleDict(\n",
       "      (0): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (2): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (3): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (4): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (5): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (6): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (7): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (8): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (9): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (10): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (11): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (12): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (13): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (14): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (15): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (16): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (17): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (18): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (19): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (20): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (21): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (22): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (23): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (24): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (25): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (26): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (27): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (28): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (29): Linear(in_features=128, out_features=2, bias=True)\n",
       "      (30): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=MTL(model_pre.to(dv),tasks=N_tasks)\n",
    "net=nn.DataParallel(net)\n",
    "net.to(dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0   Acc: tensor(0.8876) EOs: tensor(0.0050)\n",
      "Relative: tensor(1.0019) tensor(0.4657)\n",
      "Task 1   Acc: tensor(0.7363) EOs: tensor(0.0074)\n",
      "Relative: tensor(0.9845) tensor(0.4118)\n",
      "Task 2   Acc: tensor(0.5872) EOs: tensor(0.0070)\n",
      "Relative: tensor(0.9334) tensor(0.3974)\n",
      "Task 3   Acc: tensor(0.7950) EOs: tensor(0.0225)\n",
      "Relative: tensor(0.9507) tensor(0.7088)\n",
      "Task 4   Acc: tensor(0.8466) EOs: tensor(0.0270)\n",
      "Relative: tensor(0.9536) tensor(1.0353)\n",
      "Task 5   Acc: tensor(0.7637) EOs: tensor(0.0031)\n",
      "Relative: tensor(0.9600) tensor(0.9007)\n",
      "Task 6   Acc: tensor(0.7638) EOs: tensor(0.0139)\n",
      "Relative: tensor(0.9627) tensor(0.9652)\n",
      "Task 7   Acc: tensor(0.7615) EOs: tensor(0.0207)\n",
      "Relative: tensor(0.9596) tensor(1.0589)\n",
      "Task 8   Acc: tensor(0.8550) EOs: tensor(0.0276)\n",
      "Relative: tensor(0.9570) tensor(1.2180)\n",
      "Task 9   Acc: tensor(0.7924) EOs: tensor(0.0348)\n",
      "Relative: tensor(0.9588) tensor(1.1799)\n",
      "Task 10   Acc: tensor(0.8555) EOs: tensor(0.0147)\n",
      "Relative: tensor(0.9625) tensor(1.1542)\n",
      "Task 11   Acc: tensor(0.9355) EOs: tensor(0.0102)\n",
      "Relative: tensor(0.9651) tensor(1.1322)\n",
      "Task 12   Acc: tensor(0.9385) EOs: tensor(0.0385)\n",
      "Relative: tensor(0.9678) tensor(1.1221)\n",
      "Task 13   Acc: tensor(0.6241) EOs: tensor(0.0135)\n",
      "Relative: tensor(0.9548) tensor(1.6695)\n",
      "Task 14   Acc: tensor(0.5757) EOs: tensor(0.0270)\n",
      "Relative: tensor(0.9473) tensor(1.6265)\n",
      "Task 15   Acc: tensor(0.6182) EOs: tensor(0.0136)\n",
      "Relative: tensor(0.9345) tensor(1.5766)\n",
      "Task 16   Acc: tensor(0.5405) EOs: tensor(0.0240)\n",
      "Relative: tensor(0.9309) tensor(1.5709)\n",
      "Task 17   Acc: tensor(0.9594) EOs: tensor(0.0106)\n",
      "Relative: tensor(0.9347) tensor(1.5392)\n",
      "Task 18   Acc: tensor(0.8792) EOs: tensor(0.0065)\n",
      "Relative: tensor(0.9382) tensor(1.5108)\n",
      "Task 19   Acc: tensor(0.8361) EOs: tensor(0.0197)\n",
      "Relative: tensor(0.9410) tensor(1.6484)\n",
      "Task 20   Acc: tensor(0.7190) EOs: tensor(0.0162)\n",
      "Relative: tensor(0.9433) tensor(1.7842)\n",
      "Task 21   Acc: tensor(0.7269) EOs: tensor(0.0252)\n",
      "Relative: tensor(0.9458) tensor(1.7409)\n",
      "Task 22   Acc: tensor(0.9175) EOs: tensor(0.0126)\n",
      "Relative: tensor(0.9482) tensor(1.7286)\n",
      "Task 23   Acc: tensor(0.9435) EOs: tensor(0.0056)\n",
      "Relative: tensor(0.9503) tensor(1.6982)\n",
      "Task 24   Acc: tensor(0.5723) EOs: tensor(0.0130)\n",
      "Relative: tensor(0.9460) tensor(1.6482)\n",
      "Task 25   Acc: tensor(0.7934) EOs: tensor(0.0262)\n",
      "Relative: tensor(0.9479) tensor(1.6121)\n",
      "Task 26   Acc: tensor(0.6789) EOs: tensor(0.0202)\n",
      "Relative: tensor(0.9456) tensor(1.5905)\n",
      "Task 27   Acc: tensor(0.8107) EOs: tensor(0.0314)\n",
      "Relative: tensor(0.9475) tensor(1.5641)\n",
      "Task 28   Acc: tensor(0.6651) EOs: tensor(0.0114)\n",
      "Relative: tensor(0.9429) tensor(1.5391)\n",
      "Task 29   Acc: tensor(0.8797) EOs: tensor(0.0015)\n",
      "Relative: tensor(0.9448) tensor(1.5212)\n",
      "Task 30   Acc: tensor(0.9275) EOs: tensor(0.0019)\n",
      "Relative: tensor(0.9464) tensor(1.4753)\n"
     ]
    }
   ],
   "source": [
    "l2t=[]\n",
    "net.load_state_dict(torch.load('/yourpath/CelebA/model/age/Model_multi.pt'))\n",
    "pred0=net(test_batch.to(device).float())\n",
    "ra,rf=0,0\n",
    "for t in range(N_tasks):         \n",
    "    accuracy=acc(pred0[t].to(cpu),torch.tensor(y_test[t]).to(cpu))\n",
    "    DM=DM_rate(pred0[t].to(cpu),torch.tensor(y_test[t]).to(cpu),torch.tensor(g_test).to(cpu)) \n",
    "    l2t.append([accuracy,DM])\n",
    "    ra+=accuracy/Bests[t][0]\n",
    "    rf+=DM/Bests[t][1]\n",
    "    print('Task',t,'  Acc:',accuracy, 'EOs:',DM)\n",
    "    print('Relative:',ra/(t+1), rf/(t+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
