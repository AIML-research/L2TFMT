{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3,0\" #list the gpu cores in the order you want to use e.g \"0,1,2,3\"\n",
    "cpu = torch.device('cpu')#\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dv=torch.device(\"cuda\")\n",
    "\n",
    "import os\n",
    "import torch.tensor as tensor\n",
    "os.chdir(\"/yourpath/ACS_PUMS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Train and Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folktables\n",
    "from folktables import ACSDataSource\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data( download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[\n",
    "        'AGEP',\n",
    "        'SCHL',\n",
    "        'MAR',\n",
    "        #'RELSHIPP',#'RELP',\n",
    "        'DIS',\n",
    "        'ESP',\n",
    "        'CIT',\n",
    "        'MIG',\n",
    "        'MIL',\n",
    "        'ANC',\n",
    "        'NATIVITY',\n",
    "        'DEAR',\n",
    "        'DEYE',\n",
    "        'DREM',\n",
    "        'SEX',\n",
    "        'RAC1P',\n",
    "        'PUMA',\n",
    "        'ST',\n",
    "        'OCCP',\n",
    "        'JWTR',#use 'JWTRNS' for testing (2019) data for training (2018) data the feature is 'JWTR',#\n",
    "        'POWPUMA',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Employment = folktables.BasicProblem(\n",
    "     features=features,\n",
    "    target='ESR',\n",
    "    target_transform=lambda x: x == 1,\n",
    "    group='SEX',\n",
    "    preprocess=folktables.acs.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Income = folktables.BasicProblem(\n",
    "     features=features,\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 50000,\n",
    "    group='SEX',\n",
    "    preprocess=folktables.acs.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HealthInsurance = folktables.BasicProblem(\n",
    "     features=features,\n",
    "    target='HINS2',\n",
    "    target_transform=lambda x: x == 1,\n",
    "    group='SEX',\n",
    "    preprocess=folktables.acs.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TravelTime = folktables.BasicProblem(\n",
    "     features=features,\n",
    "    target=\"JWMNP\",\n",
    "    target_transform=lambda x: x > 20,\n",
    "    group='SEX',\n",
    "    preprocess=folktables.acs.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IncomePovertyRatio = folktables.BasicProblem(\n",
    "    features=features,\n",
    "    target='POVPIP',\n",
    "    target_transform=lambda x: x < 250,\n",
    "    group='SEX',\n",
    "    preprocess=folktables.acs.adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, l1, g = Employment.df_to_numpy(acs_data)\n",
    "f, l2, g = Income.df_to_numpy(acs_data)\n",
    "\n",
    "f, l3, g = HealthInsurance.df_to_numpy(acs_data)\n",
    "f, l4, g = TravelTime.df_to_numpy(acs_data)\n",
    "f, l5, g = IncomePovertyRatio.df_to_numpy(acs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array([[0 if v==False else 1 for v in l1],[0 if v==False else 1 for v in l2],[0 if v==False else 1 for v in l3],\\\n",
    "           [0 if v==False else 1 for v in l4],[0 if v==False else 1 for v in l5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=np.arange(len(f))\n",
    "X_train, X_val,in_tr,in_val  = train_test_split(f,ids, test_size=0.3,random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train,y_v=[y[i][in_tr] for i in range(len(y))],[y[i][in_val] for i in range(len(y))]\n",
    "g_train=g[in_tr]\n",
    "g_val=g[in_val]\n",
    "N_tasks=len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[torch.tensor(y_train[i]) for i in range(N_tasks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build STL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STL(nn.Module):\n",
    "\n",
    "    def __init__(self,d_in=50):\n",
    "        super(STL, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_in, 1024)  \n",
    "        self.bn1= nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.fc4 = nn.Linear(1024,1024)        \n",
    "        self.task = nn.Linear(128,2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        \n",
    "        x = F.relu(self.bn3(self.fc4(x)))\n",
    "        \n",
    "        x = F.relu(self.bn2(self.fc2(x)))        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        t = self.task(x)\n",
    "       \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fair_loss(output,target,x_control):\n",
    "    prot_att=x_control\n",
    "    index_prot=torch.squeeze(torch.nonzero(prot_att[:] != 1.))\n",
    "    target_prot=torch.index_select(target, 0, index=index_prot)\n",
    "    index_prot_pos=torch.squeeze(torch.nonzero(target_prot[:] == 1. ))\n",
    "    index_prot_neg=torch.squeeze(torch.nonzero(target_prot[:] == 0. ))\n",
    "\n",
    "    index_non_prot=torch.squeeze(torch.nonzero(prot_att[:] == 1.))\n",
    "    target_non_prot=torch.index_select(target, 0, index=index_non_prot)\n",
    "    index_non_prot_pos=torch.squeeze(torch.nonzero(target_non_prot[:] == 1. ))\n",
    "    index_non_prot_neg=torch.squeeze(torch.nonzero(target_non_prot[:] == 0. ))\n",
    "\n",
    "    l_prot_pos=F.cross_entropy(torch.index_select(output, 0, index=index_prot_pos),torch.index_select(target, 0, index=index_prot_pos))    \n",
    "    l_non_prot_pos=F.cross_entropy(torch.index_select(output, 0, index=index_non_prot_pos),torch.index_select(target, 0, index=index_non_prot_pos))    \n",
    "    l_non_prot_neg=F.cross_entropy(torch.index_select(output, 0, index=index_non_prot_neg),torch.index_select(target, 0, index=index_non_prot_neg))\n",
    "    l_prot_neg=F.cross_entropy(torch.index_select(output, 0, index=index_prot_neg),torch.index_select(target, 0, index=index_prot_neg))    \n",
    "\n",
    "    dl_pos=torch.max(l_prot_pos,l_non_prot_pos)\n",
    "    dl_neg=torch.max(l_prot_neg,l_non_prot_neg)\n",
    "    L=dl_pos+dl_neg\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "acc = torchmetrics.Accuracy()\n",
    "def DM_rate(output,target,x_control):\n",
    "    prot_att=x_control\n",
    "    index_prot=torch.squeeze(torch.nonzero(prot_att[:] != 1.))\n",
    "    target_prot=torch.index_select(target, 0, index=index_prot)\n",
    "    index_prot_pos=torch.squeeze(torch.nonzero(target_prot[:] == 1. ))\n",
    "    index_prot_neg=torch.squeeze(torch.nonzero(target_prot[:] == 0. ))\n",
    "\n",
    "    index_non_prot=torch.squeeze(torch.nonzero(prot_att[:] == 1.))\n",
    "    target_non_prot=torch.index_select(target, 0, index=index_non_prot)\n",
    "    index_non_prot_pos=torch.squeeze(torch.nonzero(target_non_prot[:] == 1. ))\n",
    "    index_non_prot_neg=torch.squeeze(torch.nonzero(target_non_prot[:] == 0. ))\n",
    "\n",
    "    l_prot_pos=acc(torch.index_select(output, 0, index=index_prot_pos),torch.index_select(target, 0, index=index_prot_pos))    \n",
    "    l_non_prot_pos=acc(torch.index_select(output, 0, index=index_non_prot_pos),torch.index_select(target, 0, index=index_non_prot_pos))    \n",
    "    l_non_prot_neg=acc(torch.index_select(output, 0, index=index_non_prot_neg),torch.index_select(target, 0, index=index_non_prot_neg))\n",
    "    l_prot_neg=acc(torch.index_select(output, 0, index=index_prot_neg),torch.index_select(target, 0, index=index_prot_neg))    \n",
    "\n",
    "    dl_pos=torch.abs(l_prot_pos-l_non_prot_pos)\n",
    "    dl_neg=torch.abs(l_prot_neg-l_non_prot_neg)\n",
    "    DM=dl_pos+dl_neg\n",
    "    \n",
    "    return DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLs=[nn.DataParallel(STL(d_in=X_train.shape[1])).to(dv) for t in range(N_tasks)]\n",
    "SL_optis=[optim.AdamW(SLs[t].parameters()) for t in range(N_tasks)]\n",
    "spaths={'path'+str(t):'/home/roy/ACS_PUMS/model/Model_stl'+str(t)+'.pt' for t in range(N_tasks)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "best_S=[[0,1] for t in range(N_tasks)]\n",
    "All_S=[[] for t in range(N_tasks)]\n",
    "SL_E=[[] for t in range(N_tasks)]\n",
    "\n",
    "for epoch in range(50):  # loop over each NN multiple times\n",
    "\n",
    "    i,batch=0,8192\n",
    "    j=0\n",
    "    while(i<len(X_train)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        if (i+batch)<len(X_train):\n",
    "            inputs, in_t = torch.tensor(X_train[i:i+batch]),in_tr[i:i+batch]\n",
    "            labels=[y_train[t][i:i+batch] for t in range(N_tasks)]#,y3_train[i:i+batch]]\n",
    "            #if epoch<pretrn:\n",
    "            xc=xg[i:i+batch]\n",
    "            i=i+batch \n",
    "        else:\n",
    "            inputs,in_t = torch.tensor(X_train[i:]),in_tr[i:]\n",
    "            labels=[y_train[t][i:] for t in range(N_tasks)]#,y2_train[i:]]#,y3_train[i:]]\n",
    "            #if epoch<pretrn:\n",
    "            xc=xg[i:]\n",
    "            i=len(X_train)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        for t in range(N_tasks):\n",
    "            ##training STLs\n",
    "            SL_optis[t].zero_grad()\n",
    "            out=SLs[t](inputs.to(dv).float())\n",
    "            loss_Sa=criteria(out, labels[t].to(dv))\n",
    "            loss_Sf=fair_loss(out, labels[t].to(dv),xc.to(dv))\n",
    "            SL_E[t].append([loss_Sa,loss_Sf])\n",
    "            loss=loss_Sa+loss_Sf\n",
    "            loss.backward()\n",
    "            SL_optis[t].step()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    with torch.no_grad():\n",
    "       \n",
    "        for t in range(N_tasks): \n",
    "            pred_SL=SLs[t](torch.tensor(X_val).to(dv).float())\n",
    "            SL_acc=acc(pred_SL.to(cpu),torch.tensor(y_v[t]).to(cpu))\n",
    "            SL_eo=DM_rate(pred_SL.to(cpu),torch.tensor(y_v[t]).to(cpu),torch.tensor(g_val).to(cpu))\n",
    "            All_S[t].append([SL_acc,SL_eo])\n",
    "            if SL_acc>best_S[t][0]:\n",
    "                best_S[t][0]=SL_acc\n",
    "                best_S[t][1]=SL_eo\n",
    "                torch.save(SLs[t].state_dict(),spaths['path'+str(t)])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
